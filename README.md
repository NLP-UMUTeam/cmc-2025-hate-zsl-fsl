# Detection of Maliciously Disseminated Hate Speech in Spanish Using Fine-Tuning and In-Context Learning Techniques with Large Language Models
The malicious dissemination of hate speech via compromised accounts, automated bot networks, and malware-driven social media campaigns has become a growing cybersecurity concern. Automatically detecting such content in Spanish poses significant challenges due to the language's linguistic complexity and the scarcity of annotated resources. In this paper, we compare two predominant AI-based approaches for the forensic detection of malicious hate speech: (1) fine-tuning encoder-only models that have been trained in Spanish and (2) In-Context Learning techniques, such as Zero- and Few-Shot Learning, with large-scale language models. Our approach goes beyond binary classification, proposing a comprehensive, multidimensional evaluation that classifies each text according to the following four criteria: (1) the type of speech (hope, hate, offensive or none), (2) the recipient (individual, group or none), (3) the level of intensity (1-5); and (4) the targeted group (e.g. homophobia, misogyny). Performance is evaluated using an annotated Spanish corpus and standard metrics such as precision, recall and F1-score are applied. The results indicate that fine-tuned encoder-only models, especially MarIA and BETO variants, provide the most robust and reliable performance across all tasks, while Zero-Shot approaches remain unstable and less effective. For its part, Few-Shot Prompting improves stability and recall to some extent with Qwen 3 8B and Mistral 7B, but still falls short of the fine-tuned models. These findings highlight the importance of supervised adaptation and discuss the potential of both paradigms as components in AI-powered cybersecurity and malware forensics systems designed to identify and mitigate coordinated online hate campaigns
